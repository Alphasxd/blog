---
layout: post
title: 🔖 隐私计算 - 肖臻(2021云栖大会)
categories: academic
---

# Privacy-Preserving Computation

---

> 内容源自[2021云栖大会-隐私计算-肖臻cut](https://www.bilibili.com/video/BV1JU4y1g7Ho/?share_source=copy_web&vd_source=9e178f716784229a31b1d46a83ef9aba)

## 隐私计算的概念

  隐私计算是指在保证数据提供方不泄露原始数据的前提下，对数据进行搜集、处理，完成数据价值挖掘的技术体系，保障数据在流通和融合过程中的“可用不可见”，有广泛的应用前景，也面临着诸多挑战。

  隐私计算融合了密码学、安全硬件、数据科学、人工智能、计算机工程等众多领域，涵盖多种技术方案，横跨了以下技术的综合性技术，目标是实现数据所有权和数据使用权的分离

- 联邦学习
- 安全多方计算
- 同态加密
- 零知识证明
- 可信执行环境

![image-20231014204944391](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/14_20_49_44_image-20231014204944391.png)

## 隐私计算的潜在需求

![image-20231014205136866](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/14_20_51_36_image-20231014205136866.png)

## 隐私计算的前进与挑战

前景

- 社会效益大，保护用户隐私
- 全球各国对数据安全高度重视
- 隐私计算的技术创新不断涌现

挑战

- 从技术角度来说，隐私计算仍然需要突破以获得更高性能
- 隐私计算的认知度，认可度仍然不足，商业模式仍然在探索中
- 隐私计算的学习成本、设备成本较高 

![image-20231014205507032](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/14_20_55_7_image-20231014205507032.png)

> 目前阶段的隐私计算只能是说实现了某些特定场景下，
>
> 针对某些功能下的隐私计算并没有实现真正意义上的通用的隐私计算

## 联邦学习

联邦学习是一种分布式机器学习技术

可以使分散的各参与方在不向其他参与者泄漏隐私数据的前提下，协作进行机器学习的模型训练，它是人工智能领域保护数据隐私性的方法，使得各方的私密数据在不出本地的情况下，能够把各方数据联合在一起共同训练一个机器学习模型，训练模型、推理模型都可以综合利用各方的数据，想法是非常好的

![image-20231014205915467](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/14_20_59_15_image-20231014205915467.png)

**联邦学习中的问题**

利益分配：医疗大数据，合作过程中的效益合同，三甲vs小县城规模不同，病例质量样本不同

数据真实性：所有隐私计算的方法中都会涉及到，假设是真实的，虚假的数据会影响收敛，甚至会成为恶意攻击者的一种攻击手段，医院的样本数量分配利益，假如小县城的医院造出一些假样本咋办，很难检测，你怎么知道是真假，你见都见不到

隐私泄漏：联邦学习已经采用了很好的方法来防止泄漏隐私，让训练数据不离开本地，但是通过此种措施就能保证数据不会泄漏吗？不一定。学术上是有一些争议的，上传的梯度信息其实可以用来反推出原始的训练数据，他们是相关的。虽然数据本身没有离开本地，但有关数据的信息还是汇聚到一个中央服务器里，仍然存在隐私泄漏的可能性。

![image-20231014211724804](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/14_21_17_24_image-20231014211724804.png)

## 安全多方计算

姚氏百万富翁问题

![image-20231014212103746](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/14_21_21_3_image-20231014212103746.png)

姚启智，两个百万富翁在街上遇到了，想要比一比谁更有钱，他们知道自己有多少钱，但是并不想透露出去，在双方不透露各有多少钱的情况下，比出谁更有钱。

假设没有可信第三方，安全多方计算的本质：既要保证各个参与方的数据隐私性，又要合在一起计算一个约定的函数

![image-20231014212527955](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/14_21_25_28_image-20231014212527955.png)

跟联邦学习有一定的相似性，但是不完全一样，这是一个形式化的描述，我们假设有n个参与方，他们各自有数据 X1，X2，，，Xn，f是一个约定好的函数，假设所有的参与方都事先商量好了，我们要一起算这个函数f得到的结果是Y1，Y2，，，Yn。第一个参与方X1，他知道自己的输入X1，同时也能获得自己的输出Y1，但是他没有办法知道其他n-1个输入X2，，，Xn，也没有办法获得其他的输出Y2，，，Yn，这是用来实现隐私保护的，对比一下这个图跟联邦学习那个图，这个模式的去中心化程度更高一点。联邦学习其实是有一个中央服务器的，这个中央服务器应该说也不算是可信第三方。因为虽然参与方把梯度的更新反馈到中央服务器上，但是原始数据并没有送过去。然而安全多方计算在很多情况下可以做到不需要中央服务器，完全是P2P结构的。

![image-20231015105305736](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/15_10_53_5_image-20231015105305736.png)

安全多方计算有很多实现相关的技术

安全多方计算的分类

**通用的安全多方计算：**

可以计算任意的约定的函数，功能很强大，但是效率很低，到目前为止，通用的安全多方计算在实际的应用中还是比较少的

![image-20231015111633947](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/15_11_16_34_image-20231015111633947.png)

**特定问题的安全多方计算：**

为了计算某个具体功能，目前情况下有一些实际应用场景

![image-20231015111822183](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/15_11_18_22_image-20231015111822183.png)

## 同态加密 Homomorphic Encryption

安全多方计算的底层技术

第一个实现全同态加密算法的科学家：Craig Gentry，也就是数据可用不可见 ，我允许你使用我的数据，但这个数据具体是什么，不能告诉你

![image-20231015112006304](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/15_11_20_6_image-20231015112006304.png)

核心思想是利用设计的加密函数，能够保证先对这个数据，进行运算然后再加密，跟先对这个数据加密之后再运算是等价的

![image-20231015112211093](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/15_11_22_11_image-20231015112211093.png)

同态加密的性质

- 没有碰撞，与哈希函数不同，应用：加密后的两个值相等==>加密前两个值也是相等的
- 隐藏的性质 hiding property，加密后这个函数值很难反推出原始的输入值，只能用蛮力一个个的去试
- 同态运算，最重要的性质，

![image-20231015112650869](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/15_11_26_50_image-20231015112650869.png)

分类

- 部分同态加密 PHE

  - Paillier 支持加法，不支持乘法
  - BGN 只支持有限的操作，只支持一次乘法，加法不限制

- 全同态加密 FHE

  图灵完备的全同态加密，复杂度太高

![image-20231015113411063](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/15_11_34_11_image-20231015113411063.png)

## 零知识证明 

![image-20231015114029504](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/15_11_40_29_image-20231015114029504.png)

举例

有一个bitcoin账户，证明这个账户是我的 => 证明我知道这个账户的私钥 => 显然不能直接告诉你私钥 => 用账户密钥对一个随机数生成签名 => 假设大家都知道我的公钥，验证一下签名即可

这样就在不透露密钥的情况下证明了我拥有对这个账户的私钥

![image-20231015114153185](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/15_11_41_53_image-20231015114153185.png)

zk-SNARK: 简明非交互式零知识证明

![image-20231015122108715](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/15_12_21_8_image-20231015122108715.png)

**两个显著的特点**

- 非交互性 Non-Interactive: 证明者不需要跟验证者交互，发一次消息即可，之前的那个比特币账户例子就不满足非交互性，通过转账交易可以改变为非交互性，转很小数量的比特币到对方账户即可，整个转账交易可以发布到整个区块链上，其他所有的参与方都可以验证，这其中是没有交互的，public verify，发布一个消息，整个区块链上都可以验证
- 简洁 Succinct: 产生的零知识证明的存储空间很小，即使它待证明的输入很大。对于节省网络带宽提升效率是很重要的，另外它的验证速度很快，往往毫秒级别就可以完成验证。天下没有免费的午餐，产生这个证明的复杂度是比较高的。

Zcash

谁给谁转账，转了多少钱，在zcash里是加密的，是不知道的

![image-20231015123107688](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/15_12_31_7_image-20231015123107688.png)

Filecoin

zk-SNARK协议的最大规模的应用，filecoin网络里每天要产生几百万个零知识证明，存储级挖矿，我帮你存东西就可以获得奖励，复制证明只要做一次，时空证明要不断的做，定期的向你证明我继续存储了当初所承诺的那些数据，罚没机制：质押一部分代币，没有及时给出时空证明就要罚没一部分当初抵押的代币。

filecoin使用zk协议，只是用来实现它的共识机制的一部分，并没有用于用户的存储的数据

![image-20231015123125099](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/15_12_31_25_image-20231015123125099.png)

以太坊的智能合约里，也没有实现真正的隐私计算，以太坊的智能合约是图灵完备的，从理论上说也是一个很好的隐私计算的应用场景，因为智能合约的一些东西都是公开的，如果有一些隐私数据想通过智能合约进行计算，可以把这些隐私数据进行同态加密然后发到智能合约里，智能合约就负责用加密后的数据进行运算，然后把结果传给我，我再加密，智能合约可以扣掉我一部分coin。愿景非常美好，但是也没有实现，原因就是通用的同态加密技术和安全多方计算目前还没有真正的大规模应用。

## TEE: 可信执行环境

硬件层面

系统层面的隐私计算技术，利用软硬件的方法构建一个隔离的安全区域，这个区域不论是存数据还是存程序，即使是本地的操作系统都没有权利擅自访问

![image-20231015124521710](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/15_12_45_21_image-20231015124521710.png)

最早跟隐私计算没有太直接的关系

最早计算机的单机安全性就用到了，比如手机上的生物解锁，指纹或者面容，存在一个安全领域是比较好的，跟手机上的其他应用隔离开

![image-20231015125002010](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/15_12_50_2_image-20231015125002010.png)

## 隐私计算与区块链

基于区块链和TEE的数据分析服务

![image-20231015125242748](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/15_12_52_42_image-20231015125242748.png)

基于区块链和MPC实现行业热点整合

![image-20231015125219269](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/15_12_52_19_image-20231015125219269.png)

## 隐私计算的其他应用

征信系统

政务开放

医疗+AI

联合营销

![image-20231015125352858](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/15_12_53_52_image-20231015125352858.png)

## 隐私计算存在的问题

数据源真实性

计算效率低

TEE的局限

虽然本身是隔离的，但是基于硬件隔离，它仍然和一些非可信的环境，比如说操作系统和一些应用程序共享一些系统资源，以前有研究表明，恶意的攻击者可以利用这些共享资源进行侧载攻击、侧信道攻击，反推出这个安全区域里一些数据和程序的信息，所以说仍然不能做到百分之百的隐私

开发难度大

![image-20231015125121186](https://gitlab.com/Sh3ldon/MyPic/-/raw/main/pictures/2023/10/15_12_51_21_image-20231015125121186.png)

## 观念混淆

比如，黑客入侵一个大公司，盗取了大量的数据

这种其实不属于隐私计算的问题，这是属于传统计算机安全领域的问题

隐私计算是说：我是数据的拥有者，我已经授权你使用这个数据，但是我没有授权你看到数据的原始状态是什么

黑客入侵根本不存在授权使用数据的过程，利用计算机安全领域的漏洞完成的攻击